{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6be4d5b-d091-43e4-b385-4cb420833ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/models/google/wiki40b-lm/tensorFlow1/id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23cb344-00a4-4ae7-b5b1-1ca67f8caa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as tf_text\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "n_layer = 12\n",
    "d_model = 768\n",
    "max_gen_len = 128\n",
    "\n",
    "def generate(module, inputs, mems):\n",
    "  \"\"\"Generate text.\"\"\"\n",
    "  inputs = tf.dtypes.cast(inputs, tf.int64)\n",
    "  generation_input_dict = dict(input_tokens=inputs)\n",
    "  mems_dict = {}\n",
    "  for i in range(n_layer):\n",
    "    mems_dict[\"mem_{}\".format(i)] = mems[i]\n",
    "  generation_input_dict.update(mems_dict)\n",
    "\n",
    "  generation_outputs = module(generation_input_dict, signature=\"prediction\",\n",
    "                              as_dict=True)\n",
    "  probs = generation_outputs[\"probs\"]\n",
    "\n",
    "  new_mems = []\n",
    "  for i in range(n_layer):\n",
    "    new_mems.append(generation_outputs[\"new_mem_{}\".format(i)])\n",
    "\n",
    "  return probs, new_mems\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "  module = hub.Module(\"https://www.kaggle.com/models/google/wiki40b-lm/TensorFlow1/id/1\")\n",
    "  text = [\"\\n_START_ARTICLE_\\n(257195) 2008 QY41\\n_START_SECTION_\\nPembentukan\\n_START_PARAGRAPH_\\nSeperti asteroid secara keseluruhan, asteroid ini terbentuk dari nebula matahari primordial sebagai pecahan planetisimal, sesuatu di\"]\n",
    "\n",
    "  # Word embeddings.\n",
    "  embeddings = module(dict(text=text), signature=\"word_embeddings\",\n",
    "                      as_dict=True)\n",
    "  embeddings = embeddings[\"word_embeddings\"]\n",
    "\n",
    "  # Activations at each layer.\n",
    "  activations = module(dict(text=text),signature=\"activations\", as_dict=True)\n",
    "  activations = activations[\"activations\"]\n",
    "\n",
    "  # Negative log likelihood of the text, and perplexity.\n",
    "  neg_log_likelihood = module(dict(text=text), signature=\"neg_log_likelihood\",\n",
    "                              as_dict=True)\n",
    "  neg_log_likelihood = neg_log_likelihood[\"neg_log_likelihood\"]\n",
    "  ppl = tf.exp(tf.reduce_mean(neg_log_likelihood, axis=1))\n",
    "\n",
    "  # Tokenization and detokenization with the sentencepiece model.\n",
    "  token_ids = module(dict(text=text), signature=\"tokenization\", as_dict=True)\n",
    "  token_ids = token_ids[\"token_ids\"]\n",
    "\n",
    "  detoken_text = module(dict(token_ids=token_ids), signature=\"detokenization\",\n",
    "                        as_dict=True)\n",
    "  detoken_text = detoken_text[\"text\"]\n",
    "\n",
    "  # Generation\n",
    "  mems_np = [np.zeros([1, 0, d_model], dtype=np.float32) for _ in range(n_layer)]\n",
    "  inputs_np = token_ids\n",
    "  sampled_ids = []\n",
    "  for step in range(max_gen_len):\n",
    "    probs, mems_np = generate(module, inputs_np, mems_np)\n",
    "    sampled_id = tf.random.categorical(tf.math.log(probs[0]), num_samples=1, dtype=tf.int32)\n",
    "    sampled_id = tf.squeeze(sampled_id)\n",
    "\n",
    "    sampled_ids.append(sampled_id)\n",
    "    inputs_np = tf.reshape(sampled_id, [1, 1])\n",
    "\n",
    "  sampled_ids = tf.expand_dims(sampled_ids, axis=0)\n",
    "  generated_text = module(dict(token_ids=sampled_ids),\n",
    "                          signature=\"detokenization\", as_dict=True)\n",
    "  generated_text = generated_text[\"text\"]\n",
    "\n",
    "  init_op = tf.group([tf.global_variables_initializer(),\n",
    "                      tf.tables_initializer()])\n",
    "\n",
    "# Initialize session.\n",
    "with tf.Session(graph=g) as session:\n",
    "  session.run(init_op)\n",
    "  embeddings, neg_log_likelihood, ppl, activations, token_ids, detoken_text, generated_text = session.run([\n",
    "    embeddings, neg_log_likelihood, ppl, activations, token_ids, detoken_text, generated_text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41cfb1a-6ea6-4b8c-857e-b82291d5cc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.model_download(\"google/wiki40b-lm/tensorFlow1/id\")\n",
    "\n",
    "print(\"Path to model files:\", path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
